{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile ~/.theanorc\n",
    "[global]\n",
    "device=gpu\n",
    "floatX=float32\n",
    "\n",
    "[blas]\n",
    "ldflags=-lopenblas\n",
    "\n",
    "[cuda]\n",
    "root=/opt/apps/cuda/7.0\n",
    "\n",
    "[nvcc]\n",
    "fastmath=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cPickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.objectives import squared_error\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import BatchIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load(\"/work/02735/edwardk/classify/data/training_images.small.npy\")\n",
    "print(\"X.shape = {}, X.min = {}, X.max = {}\".format(X.shape, X.min(), X.max()))\n",
    "\n",
    "y = np.load(\"/work/02735/edwardk/classify/data/training_labels.small.npy\")\n",
    "print(\"y.shape = {}, y.min = {}, y.max = {}\".format(y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def renormalize(array):\n",
    "    return (array - array.min()) / (array.max() - array.min())\n",
    "\n",
    "for i in range(5):\n",
    "    X[:, i, :, :] = renormalize(X[:, i, :, :])\n",
    "    \n",
    "y = renormalize(y)\n",
    "\n",
    "print(\"X.shape = {}, X.min = {}, X.max = {}\".format(X.shape, X.min(), X.max()))\n",
    "print(\"y.shape = {}, y.min = {}, y.max = {}\".format(y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_PCA(array):\n",
    "\n",
    "    nimages0, nchannels0, height0, width0 = array.shape\n",
    "    rolled = np.transpose(array, (0, 2, 3, 1))\n",
    "    # transpose from N x channels x height x width  to  N x height x width x channels\n",
    "    nimages1, height1, width1, nchannels1 = rolled.shape\n",
    "    # check shapes\n",
    "    assert nimages0 == nimages1\n",
    "    assert nchannels0 == nchannels1\n",
    "    assert height0 == height1\n",
    "    assert width0 == width1\n",
    "    # flatten\n",
    "    reshaped = rolled.reshape(nimages1 * height1 * width1, nchannels1)\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    pca = PCA()\n",
    "    pca.fit(reshaped)\n",
    "    \n",
    "    cov = pca.get_covariance()\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "    \n",
    "    return eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AugmentedBatchIterator(BatchIterator):\n",
    "    \n",
    "    def __init__(self, batch_size, crop_size=8, testing=False):\n",
    "        super(AugmentedBatchIterator, self).__init__(batch_size)\n",
    "        self.crop_size = crop_size\n",
    "        self.testing = testing\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "\n",
    "        Xb, yb = super(AugmentedBatchIterator, self).transform(Xb, yb)\n",
    "        batch_size, nchannels, width, height = Xb.shape\n",
    "        \n",
    "        if self.testing:\n",
    "            if self.crop_size % 2 == 0:\n",
    "                right = left = self.crop_size // 2\n",
    "            else:\n",
    "                right = self.crop_size // 2\n",
    "                left = self.crop_size // 2 + 1\n",
    "            X_new = Xb[:, :, right: -left, right: -left]\n",
    "            return X_new, yb\n",
    "\n",
    "        eigenvalues, eigenvectors = compute_PCA(Xb)\n",
    "\n",
    "        # Flip half of the images horizontally at random\n",
    "        indices = np.random.choice(batch_size, batch_size // 2, replace=False)        \n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "\n",
    "        # Crop images\n",
    "        X_new = np.zeros(\n",
    "            (batch_size, nchannels, width - self.crop_size, height - self.crop_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Choose x, y pixel posiitions at random\n",
    "            px, py = np.random.choice(self.crop_size, size=2)\n",
    "                \n",
    "            sx = slice(px, px + width - self.crop_size)\n",
    "            sy = slice(py, py + height - self.crop_size)\n",
    "            \n",
    "            # Rotate 0, 90, 180, or 270 degrees at random\n",
    "            nrotate = np.random.choice(4)\n",
    "            \n",
    "            # add random color perturbation\n",
    "            alpha = np.random.normal(loc=0.0, scale=0.5, size=5)\n",
    "            noise = np.dot(eigenvectors, np.transpose(alpha * eigenvalues))\n",
    "            \n",
    "            for j in range(nchannels):\n",
    "                X_new[i, j] = np.rot90(Xb[i, j, sx, sy] + noise[j], k=nrotate)\n",
    "                \n",
    "        return X_new, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SaveParams(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if train_history[-1][\"valid_loss_best\"]:\n",
    "            nn.save_params_to(\"{}.params\".format(self.name))\n",
    "            with open(\"{}.history\".format(self.name), \"w\") as f:\n",
    "                pickle.dump(train_history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the `verbose` parameter to `2`.\n",
    "\n",
    "# 4 dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net49 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "\n",
    "        ('conv11', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "\n",
    "        ('conv21', layers.Conv2DLayer),\n",
    "        ('conv22', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "\n",
    "        ('conv31', layers.Conv2DLayer),\n",
    "        ('conv32', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('dropout4', layers.DropoutLayer),\n",
    "        \n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('dropout5', layers.DropoutLayer),\n",
    "\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 5, 44, 44),\n",
    "    \n",
    "    conv11_num_filters=32, conv11_filter_size=(5, 5), \n",
    "    pool1_pool_size=(2, 2),\n",
    "\n",
    "    conv21_num_filters=64, conv21_filter_size=(3, 3),\n",
    "    conv22_num_filters=64, conv22_filter_size=(3, 3),\n",
    "    pool2_pool_size=(2, 2),\n",
    "\n",
    "    conv31_num_filters=128, conv31_filter_size=(3, 3),\n",
    "    conv32_num_filters=128, conv32_filter_size=(3, 3),\n",
    "    pool3_pool_size=(2, 2),\n",
    "\n",
    "    hidden4_num_units=2048,\n",
    "    dropout4_p=0.5,\n",
    "    \n",
    "    hidden5_num_units=2048,\n",
    "    dropout5_p=0.5,\n",
    "\n",
    "    output_num_units=1,\n",
    "    output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=0.0001,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    objective_loss_function=squared_error,\n",
    "    regression=True,\n",
    "    max_epochs=1000,\n",
    "    batch_iterator_train=AugmentedBatchIterator(batch_size=128, crop_size=4),\n",
    "    batch_iterator_test=AugmentedBatchIterator(batch_size=128, crop_size=4, testing=True),\n",
    "\n",
    "    on_epoch_finished=[SaveParams(\"net49\")],\n",
    "\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net49.load_params_from(\"net48.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net49.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_valid_loss = min([row['valid_loss'] for row in net49.train_history_])\n",
    "print(\"Best valid loss: {}\".format(best_valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(net):\n",
    "    train_loss = [row['train_loss'] for row in net.train_history_]\n",
    "    valid_loss = [row['valid_loss'] for row in net.train_history_]\n",
    "    plt.semilogy(train_loss, label='train loss')\n",
    "    plt.semilogy(valid_loss, label='valid loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(net49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.load(\"/work/02735/edwardk/classify/data/test_images.small.npy\")\n",
    "y_test = np.load(\"/work/02735/edwardk/classify/data/test_labels.small.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X_test[:, i, :, :] = renormalize(X_test[:, i, :, :])\n",
    "    \n",
    "y_test = renormalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = net49.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0\n",
    "y_pred[y_pred > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"net49_pred.npy\", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
